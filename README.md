# Apache Spark Examples

This project demonstrates the use of Apache Spark for distributed data processing. The examples cover:
1. **RDD API**: A Word Count program using Resilient Distributed Datasets (RDDs).
2. **DataFrame API**: A SQL Query example using Spark's DataFrame and SQL functionality.
3. **Structured Streaming API**: Real-time data processing using Spark's Structured Streaming.

## **Prerequisites**

To run this project, you need the following installed on your machine:
- **Apache Spark 3.x**: [Download Spark](https://spark.apache.org/downloads.html)
- **Python 3.x**
- **Java 8 or 11**

Install the required Python library for Spark:
```bash
pip install pyspark
